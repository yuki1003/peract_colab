{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training PerAct Agent on handoversim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.bool = np.bool_ # bad trick to fix numpy version issue :(\n",
    "import os\n",
    "import sys\n",
    "from natsort import natsorted\n",
    "\n",
    "sys.path = [p for p in sys.path if '/peract/' not in p]\n",
    "\n",
    "# Set `PYOPENGL_PLATFORM=egl` for pyrender visualizations\n",
    "os.environ[\"DISPLAY\"] = \":0\"\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,3\" #\"0,1,2,3\" # Depends on your computer and available GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "\n",
    "# available_cameras = [f\"view_{camera_i}\" for camera_i in range(12)]\n",
    "\n",
    "# # Grid search\n",
    "# grid = {\n",
    "#     'fill_replay_setting': [\"crop\"],#, \"standard\", \"uniform\"],\n",
    "#     'cameras': [available_cameras[6:][::2],\n",
    "#                 available_cameras[6:],\n",
    "#                 available_cameras[:6],\n",
    "#                 available_cameras[1::2][:3]+available_cameras[0::2][3:],\n",
    "#                 available_cameras[:6][-2:]+available_cameras[6:][:4]],\n",
    "#     'RGB_AUGMENTATION': ['None'],#,'partial','full'],\n",
    "#     'demo_augm_n': [5],\n",
    "#     'keypoint_approach': [True],#, False],\n",
    "#     'data': ['handoversim_v4'],\n",
    "#     # 'only_learn_approach': [True]\n",
    "# }\n",
    "# # Loop over al grid search combinations\n",
    "# counter = 0\n",
    "# lst_settings = []\n",
    "# for values in itertools.product(*grid.values()):\n",
    "    \n",
    "#     point = dict(zip(grid.keys(), values))\n",
    "#     # merge the general settings\n",
    "#     settings = {**point}\n",
    "#     lst_settings.append(settings)\n",
    "#     print(counter, settings)\n",
    "#     counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from notebook_helpers.constants import BATCH_SIZE\n",
    "# from notebook_helpers.build_replay import load_replay_buffer\n",
    "# from notebook_helpers.build_training import build_agent, agent_training\n",
    "\n",
    "# if BATCH_SIZE != 2:\n",
    "#     raise ValueError(\"BATCH_SIZE must be 2 for this notebook\")\n",
    "\n",
    "# # Loop over al grid search combinations: and run\n",
    "# for run_settings in lst_settings:\n",
    "#     print(run_settings)\n",
    "\n",
    "#     # --- load data and arguments: from constants ---\n",
    "\n",
    "#     # STATIC VALUES USED IN BELOW FUNCTION: SETTING THEM AS GLOBAL FOR FURTHER USE\n",
    "#     # ___DATA___\n",
    "\n",
    "#     # Data constants\n",
    "\n",
    "#     EPISODE_FOLDER = 'episode%d'\n",
    "#     SETUP = \"s1\" # Options: \"s1\"\n",
    "\n",
    "#     # Data folder\n",
    "#     WORKSPACE_DIR = os.getcwd()\n",
    "#     DATA_FOLDER = os.path.join(WORKSPACE_DIR, \"task_data\", \"handoversim_v4\")\n",
    "#     DATA_FOLDER = DATA_FOLDER.replace(\"/peract_colab\", \"\")\n",
    "    \n",
    "#     REFERENCE_TASKS_DIR = os.path.join(DATA_FOLDER, \"train_{}\".format(SETUP))\n",
    "#     ALL_TASKS = os.listdir(REFERENCE_TASKS_DIR)\n",
    "#     for TASK_i, TASK in enumerate(ALL_TASKS):\n",
    "#         if not TASK in [\"handing_over_pitcher_base\"]:\n",
    "#             continue\n",
    "\n",
    "#         EPISODES_FOLDER = os.path.join(TASK, \"all_variations\", \"episodes\")\n",
    "\n",
    "#         train_data_path = os.path.join(DATA_FOLDER, f\"train_{SETUP}\", EPISODES_FOLDER)\n",
    "#         TRAIN_INDEXES = [int(episode_nr.replace(\"episode\", \"\")) for episode_nr in natsorted(os.listdir(train_data_path))]\n",
    "#         test_data_path = os.path.join(DATA_FOLDER, f\"val_{SETUP}\", EPISODES_FOLDER)\n",
    "#         TEST_INDEXES = [int(episode_nr.replace(\"episode\", \"\")) for episode_nr in natsorted(os.listdir(test_data_path))]\n",
    "\n",
    "#         print(f\"\\nTASK: ({TASK_i} / {len(ALL_TASKS)}): {TASK} ______________________\")\n",
    "#         print(f\"TRAIN | Total #: {len(TRAIN_INDEXES)}, indices: {TRAIN_INDEXES}\")\n",
    "#         print(f\"TEST | Total #: {len(TEST_INDEXES)}, indices: {TEST_INDEXES}\")\n",
    "\n",
    "#         train_data_iter, test_data_iter = load_replay_buffer(run_settings,\n",
    "#                                                              WORKSPACE_DIR, SETUP, EPISODE_FOLDER,\n",
    "#                                                              TASK,\n",
    "#                                                              train_data_path, test_data_path, TRAIN_INDEXES, TEST_INDEXES)\n",
    "#         peract_agent = build_agent(run_settings)\n",
    "#         agent_training(run_settings, peract_agent, train_data_iter, test_data_iter, WORKSPACE_DIR, TASK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For single (test) run\n",
    "# available_cameras = [f\"view_{camera_i}\" for camera_i in range(3)]\n",
    "# run_settings = {\n",
    "#     'fill_replay_setting': \"crop\",\n",
    "#     'cameras': available_cameras,\n",
    "#     'RGB_AUGMENTATION': 'partial',\n",
    "#     'keypoint_approach': True,\n",
    "#     'demo_augm_n': 5,\n",
    "#     'only_learn_approach': True\n",
    "# }\n",
    "# print(run_settings)\n",
    "\n",
    "# train_data_iter, test_data_iter = load_replay_buffer(run_settings)\n",
    "# peract_agent = build_agent(run_settings)\n",
    "# agent_training(run_settings, peract_agent, train_data_iter, test_data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing object specific grasp locations (mug: handle vs. rim)\n",
    "\n",
    "import itertools\n",
    "\n",
    "available_cameras = [f\"view_{camera_i}\" for camera_i in range(12)]\n",
    "\n",
    "# Grid search\n",
    "grid = {\n",
    "    'fill_replay_setting': [\"crop\"],#, \"standard\", \"uniform\"],\n",
    "    'cameras': [#available_cameras[6:][::2]],\n",
    "                # available_cameras[6:],\n",
    "                # available_cameras[:6],\n",
    "                # available_cameras[1::2][:3]+available_cameras[0::2][3:],\n",
    "                available_cameras[:6][-2:]+available_cameras[6:][:4]],\n",
    "    'RGB_AUGMENTATION': ['None'],#,'partial','full'],\n",
    "    'demo_augm_n': [5],\n",
    "    'keypoint_approach': [True],#, False],\n",
    "    'data': ['handoversim_v4'],\n",
    "    'test': ['mug - grasp the handle'],\n",
    "    'loss_computation': ['total = trans + rot'],\n",
    "    'validation': ['remove out of distribution episode 466']\n",
    "    # 'only_learn_approach': [True]\n",
    "}\n",
    "# Loop over al grid search combinations\n",
    "counter = 0\n",
    "lst_settings = []\n",
    "for values in itertools.product(*grid.values()):\n",
    "    \n",
    "    point = dict(zip(grid.keys(), values))\n",
    "    # merge the general settings\n",
    "    settings = {**point}\n",
    "    lst_settings.append(settings)\n",
    "    print(counter, settings)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing object specific grasp locations (mug: handle vs. rim)\n",
    "\n",
    "from notebook_helpers.constants import BATCH_SIZE\n",
    "from notebook_helpers.build_replay import load_replay_buffer\n",
    "from notebook_helpers.build_training import build_agent, agent_training\n",
    "\n",
    "if BATCH_SIZE != 2:\n",
    "    raise ValueError(\"BATCH_SIZE must be 2 for this notebook\")\n",
    "\n",
    "# Loop over al grid search combinations: and run\n",
    "for run_settings in lst_settings:\n",
    "    print(run_settings)\n",
    "\n",
    "    # --- load data and arguments: from constants ---\n",
    "\n",
    "    # STATIC VALUES USED IN BELOW FUNCTION: SETTING THEM AS GLOBAL FOR FURTHER USE\n",
    "    # ___DATA___\n",
    "\n",
    "    # Data constants\n",
    "\n",
    "    EPISODE_FOLDER = 'episode%d'\n",
    "    SETUP = \"s1\" # Options: \"s1\"\n",
    "\n",
    "    # Data folder\n",
    "    WORKSPACE_DIR = os.getcwd()\n",
    "    DATA_FOLDER = os.path.join(WORKSPACE_DIR, \"task_data\", \"handoversim_v4\")\n",
    "    DATA_FOLDER = DATA_FOLDER.replace(\"/peract_colab\", \"\")\n",
    "    \n",
    "    REFERENCE_TASKS_DIR = os.path.join(DATA_FOLDER, \"train_{}\".format(SETUP))\n",
    "    ALL_TASKS = os.listdir(REFERENCE_TASKS_DIR)\n",
    "    for TASK_i, TASK in enumerate(ALL_TASKS):\n",
    "        if not TASK in [\"handing_over_mug\"]:\n",
    "            continue\n",
    "\n",
    "        EPISODES_FOLDER = os.path.join(TASK, \"all_variations\", \"episodes\")\n",
    "\n",
    "        train_data_path = os.path.join(DATA_FOLDER, f\"train_{SETUP}\", EPISODES_FOLDER)\n",
    "        test_data_path = os.path.join(DATA_FOLDER, f\"train_{SETUP}\", EPISODES_FOLDER)\n",
    "        TRAIN_INDEXES = [66, 266, 268, 269, 368] # handle\n",
    "        TEST_INDEXES = [465]#, 466] # handle\n",
    "\n",
    "        # TRAIN_INDEXES = TRAIN_INDEXES + [167, 169, 265, 365, 366, 367, 369, 468, 566, 567, 568, 569] # rim\n",
    "        # TEST_INDEXES = TEST_INDEXES + [966, 967, 968] # rim\n",
    "\n",
    "        print(f\"\\nTASK: ({TASK_i} / {len(ALL_TASKS)}): {TASK} ______________________\")\n",
    "        print(f\"TRAIN | Total #: {len(TRAIN_INDEXES)}, indices: {TRAIN_INDEXES}\")\n",
    "        print(f\"TEST | Total #: {len(TEST_INDEXES)}, indices: {TEST_INDEXES}\")\n",
    "\n",
    "        train_data_iter, test_data_iter = load_replay_buffer(run_settings,\n",
    "                                                             WORKSPACE_DIR, SETUP, EPISODE_FOLDER,\n",
    "                                                             TASK,\n",
    "                                                             train_data_path, test_data_path, TRAIN_INDEXES, TEST_INDEXES)\n",
    "        peract_agent = build_agent(run_settings)\n",
    "        agent_training(run_settings, peract_agent, train_data_iter, test_data_iter, WORKSPACE_DIR, TASK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
