{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.bool = np.bool_ # bad trick to fix numpy version issue :(\n",
    "import os\n",
    "import sys\n",
    "from natsort import natsorted\n",
    "\n",
    "sys.path = [p for p in sys.path if '/peract/' not in p]\n",
    "\n",
    "# Set `PYOPENGL_PLATFORM=egl` for pyrender visualizations\n",
    "os.environ[\"DISPLAY\"] = \":0\"\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,3\" # Depends on your computer and available GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Depending on your workspace, you may already have this repository installe, otherwise clone once again\n",
    "if not os.path.exists(os.path.join(os.getcwd(), 'peract_colab')):\n",
    "    !git clone https://github.com/yuki1003/peract_colab.git\n",
    "\n",
    "!cd peract_colab && git pull origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if modules in peract_colab repository are recognized.\n",
    "try: # test import\n",
    "    from rlbench.utils import get_stored_demo\n",
    "except ImportError as error_message:\n",
    "    print(error_message)\n",
    "    print(\"Adding peract_colab repository to system path.\")\n",
    "    sys.path.append('peract_colab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "import torch\n",
    "import clip\n",
    "\n",
    "from arm.replay_buffer import create_replay, fill_replay, uniform_fill_replay, fill_replay_copy_with_crop_from_approach, fill_replay_only_approach_test\n",
    "from yarr.replay_buffer.wrappers.pytorch_replay_buffer import PyTorchReplayBuffer\n",
    "\n",
    "from agent.perceiver_io import PerceiverIO\n",
    "from agent.peract_agent import PerceiverActorAgent\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STATIC VALUES USED IN BELOW FUNCTION: SETTING THEM AS GLOBAL FOR FURTHER USE\n",
    "\n",
    "#___DATA___\n",
    "TASK = 'handing_over_banana'\n",
    "\n",
    "# Data Constants\n",
    "WORKSPACE_DIR = os.getcwd()\n",
    "DATA_FOLDER = os.path.join(WORKSPACE_DIR, \"task_data\", \"handoversim\")\n",
    "EPISODES_FOLDER = os.path.join(TASK, \"all_variations\", \"episodes\")\n",
    "\n",
    "EPISODE_FOLDER = 'episode%d'\n",
    "SETUP = \"s1\" # Options: \"s1\"\n",
    "train_data_path = os.path.join(DATA_FOLDER, f\"train_{SETUP}\", EPISODES_FOLDER)\n",
    "TRAIN_INDEXES = [int(episode_nr.replace(\"episode\", \"\")) for episode_nr in natsorted(os.listdir(train_data_path))]\n",
    "test_data_path = os.path.join(DATA_FOLDER, f\"val_{SETUP}\", EPISODES_FOLDER)\n",
    "TEST_INDEXES = [int(episode_nr.replace(\"episode\", \"\")) for episode_nr in natsorted(os.listdir(test_data_path))]\n",
    "\n",
    "print(f\"TRAIN | Total #: {len(TRAIN_INDEXES)}, indices: {TRAIN_INDEXES}\")\n",
    "print(f\"TEST | Total #: {TEST_INDEXES}\")\n",
    "\n",
    "# Replaybuffer related constants\n",
    "LOW_DIM_SIZE = 4    # 4 dimensions - proprioception: {gripper_open, left_finger_joint, right_finger_joint, timestep}\n",
    "IMAGE_SIZE =  128  # 128x128 - if you want to use higher voxel resolutions like 200^3, you might want to regenerate the dataset with larger images\n",
    "# DEMO_AUGMENTATION_EVERY_N = 5#10 NOTE CHANGED through setting # Only select every n-th frame to use for replaybuffer from demo\n",
    "ROTATION_RESOLUTION = 5 # degree increments per axis\n",
    "TARGET_OBJ_KEYPOINTS=False # Real - (changed later)\n",
    "TARGET_OBJ_USE_LAST_KP=False # Real - (changed later)\n",
    "TARGET_OBJ_IS_AVAIL = True # HandoverSim - (changed later)\n",
    "\n",
    "DEPTH_SCALE = 1000\n",
    "STOPPING_DELTA = 0.001\n",
    "SCENE_BOUNDS = [0.11, -0.5, 0.8, 1.11, 0.5, 1.8]  # Must be 1m each\n",
    "\n",
    "# Training Settings Constants\n",
    "BATCH_SIZE = 2\n",
    "TRAINING_ITERATIONS = 10000\n",
    "LEARNING_RATE = 0.001\n",
    "TRANSFORM_AUGMENTATION = True\n",
    "\n",
    "\n",
    "# Unused training settings\n",
    "LR_SCHEDULER = False\n",
    "NUM_WARMUP_STEPS = 300  # LR_SCHEDULER: losses seem to stabilize after ~300 iterations\n",
    "NUM_CYCLES = 1  # As per: https://github.com/peract/peract/blob/02fb87681c5a47be9dbf20141bedb836ee2d3ef9/agents/peract_bc/qattention_peract_bc_agent.py#L232\n",
    "VOXEL_SIZES = [100]  # 100x100x100 voxels\n",
    "NUM_LATENTS = 512  # PerceiverIO latents: lower-dimension features of input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_peract_agent(settings):\n",
    "\n",
    "    # BATCH SETTINGS\n",
    "    FILL_REPLAY_SETTING = settings['fill_replay_setting']\n",
    "    CAMERAS = settings['cameras']\n",
    "    RGB_AUGMENTATION = settings['RGB_AUGMENTATION']\n",
    "    USE_APPROACH = settings['keypoint_approach']\n",
    "    DEMO_AUGMENTATION_EVERY_N = settings['demo_augm_n']\n",
    "\n",
    "    # Summary of run properties\n",
    "    print(\"\\nExperiment Setup\")\n",
    "    print(f\"Task: {TASK} - SETUP: {SETUP} - Cameras: {len(CAMERAS)}\")\n",
    "    print(\"Run Properties\")\n",
    "    print(f\"TrAugm: {TRANSFORM_AUGMENTATION} - RGBAugm: {RGB_AUGMENTATION} -Uniform: {FILL_REPLAY_SETTING}\")\n",
    "\n",
    "    #___REPLAY-BUFFER___\n",
    "    train_replay_storage_dir = os.path.join(WORKSPACE_DIR,'replay_train')\n",
    "    if os.path.exists(train_replay_storage_dir):\n",
    "        print(f\"Emptying {train_replay_storage_dir}\")\n",
    "        shutil.rmtree(train_replay_storage_dir)\n",
    "    if not os.path.exists(train_replay_storage_dir):\n",
    "        print(f\"Could not find {train_replay_storage_dir}, creating directory.\")\n",
    "        os.mkdir(train_replay_storage_dir)\n",
    "\n",
    "    test_replay_storage_dir = os.path.join(WORKSPACE_DIR,'replay_test')\n",
    "    if os.path.exists(test_replay_storage_dir):\n",
    "        print(f\"Emptying {test_replay_storage_dir}\")\n",
    "        shutil.rmtree(test_replay_storage_dir)\n",
    "    if not os.path.exists(test_replay_storage_dir):\n",
    "        print(f\"Could not find {test_replay_storage_dir}, creating directory.\")\n",
    "        os.mkdir(test_replay_storage_dir)\n",
    "\n",
    "    train_replay_buffer = create_replay(batch_size=BATCH_SIZE,\n",
    "                                        timesteps=1,\n",
    "                                        save_dir=train_replay_storage_dir,\n",
    "                                        cameras=CAMERAS,\n",
    "                                        voxel_sizes=VOXEL_SIZES,\n",
    "                                        image_size=IMAGE_SIZE,\n",
    "                                        low_dim_size=LOW_DIM_SIZE)\n",
    "\n",
    "    test_replay_buffer = create_replay(batch_size=BATCH_SIZE,\n",
    "                                    timesteps=1,\n",
    "                                    save_dir=test_replay_storage_dir,\n",
    "                                    cameras=CAMERAS,\n",
    "                                    voxel_sizes=VOXEL_SIZES,\n",
    "                                    image_size=IMAGE_SIZE,\n",
    "                                    low_dim_size=LOW_DIM_SIZE)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    clip_model, preprocess = clip.load(\"RN50\", device=device) # CLIP-ResNet50\n",
    "\n",
    "    print(\"-- Train Buffer --\")\n",
    "    if FILL_REPLAY_SETTING.lower() == \"uniform\":\n",
    "        uniform_fill_replay(\n",
    "            data_path=train_data_path,\n",
    "            episode_folder=EPISODE_FOLDER,\n",
    "            replay=train_replay_buffer,\n",
    "            # start_idx=0,\n",
    "            # num_demos=NUM_DEMOS,\n",
    "            d_indexes=TRAIN_INDEXES,\n",
    "            demo_augmentation=True,\n",
    "            demo_augmentation_every_n=DEMO_AUGMENTATION_EVERY_N,\n",
    "            cameras=CAMERAS,\n",
    "            rlbench_scene_bounds=SCENE_BOUNDS,\n",
    "            voxel_sizes=VOXEL_SIZES,\n",
    "            rotation_resolution=ROTATION_RESOLUTION,\n",
    "            crop_augmentation=False,\n",
    "            depth_scale=DEPTH_SCALE,\n",
    "            use_approach=USE_APPROACH,\n",
    "            approach_distance=0.3,\n",
    "            stopping_delta=STOPPING_DELTA,\n",
    "            target_obj_keypoint=TARGET_OBJ_KEYPOINTS,\n",
    "            target_obj_use_last_kp=TARGET_OBJ_USE_LAST_KP,\n",
    "            target_obj_is_avail=TARGET_OBJ_IS_AVAIL,\n",
    "            clip_model=clip_model,\n",
    "            device=device,\n",
    "            )\n",
    "    elif FILL_REPLAY_SETTING.lower() == \"crop\":\n",
    "        fill_replay_copy_with_crop_from_approach(\n",
    "            data_path=train_data_path,\n",
    "            episode_folder=EPISODE_FOLDER,\n",
    "            replay=train_replay_buffer,\n",
    "            # start_idx=0,\n",
    "            # num_demos=NUM_DEMOS,\n",
    "            d_indexes=TRAIN_INDEXES,\n",
    "            demo_augmentation=True,\n",
    "            demo_augmentation_every_n=DEMO_AUGMENTATION_EVERY_N,\n",
    "            cameras=CAMERAS,\n",
    "            rlbench_scene_bounds=SCENE_BOUNDS,\n",
    "            voxel_sizes=VOXEL_SIZES,\n",
    "            rotation_resolution=ROTATION_RESOLUTION,\n",
    "            crop_augmentation=False,\n",
    "            depth_scale=DEPTH_SCALE,\n",
    "            use_approach=USE_APPROACH,\n",
    "            approach_distance=0.3,\n",
    "            stopping_delta=STOPPING_DELTA,\n",
    "            target_obj_keypoint=TARGET_OBJ_KEYPOINTS,\n",
    "            target_obj_use_last_kp=TARGET_OBJ_USE_LAST_KP,\n",
    "            target_obj_is_avail=TARGET_OBJ_IS_AVAIL,\n",
    "            clip_model=clip_model,\n",
    "            device=device,\n",
    "            )\n",
    "    elif FILL_REPLAY_SETTING.lower() == \"standard\":\n",
    "        fill_replay_only_approach_test(\n",
    "        # fill_replay(\n",
    "            data_path=train_data_path,\n",
    "            episode_folder=EPISODE_FOLDER,\n",
    "            replay=train_replay_buffer,\n",
    "            # start_idx=0,\n",
    "            # num_demos=NUM_DEMOS,\n",
    "            d_indexes=TRAIN_INDEXES,\n",
    "            demo_augmentation=True,\n",
    "            demo_augmentation_every_n=DEMO_AUGMENTATION_EVERY_N,\n",
    "            cameras=CAMERAS,\n",
    "            rlbench_scene_bounds=SCENE_BOUNDS,\n",
    "            voxel_sizes=VOXEL_SIZES,\n",
    "            rotation_resolution=ROTATION_RESOLUTION,\n",
    "            crop_augmentation=False,\n",
    "            depth_scale=DEPTH_SCALE,\n",
    "            use_approach=USE_APPROACH,\n",
    "            approach_distance=0.3,\n",
    "            stopping_delta=STOPPING_DELTA,\n",
    "            target_obj_keypoint=TARGET_OBJ_KEYPOINTS,\n",
    "            target_obj_use_last_kp=TARGET_OBJ_USE_LAST_KP,\n",
    "            target_obj_is_avail=TARGET_OBJ_IS_AVAIL,\n",
    "            clip_model=clip_model,\n",
    "            device=device,\n",
    "            )\n",
    "    else:\n",
    "        raise ValueError(\"Unkown setting for fill replay buffer\")\n",
    "\n",
    "        \n",
    "    print(\"-- Test Buffer --\")\n",
    "    if FILL_REPLAY_SETTING.lower() == \"uniform\":\n",
    "        uniform_fill_replay(\n",
    "            data_path=test_data_path,\n",
    "            episode_folder=EPISODE_FOLDER,\n",
    "            replay=test_replay_buffer,\n",
    "            # start_idx=start_idx,\n",
    "            # num_demos=num_demos,\n",
    "            d_indexes=TEST_INDEXES,\n",
    "            demo_augmentation=True,\n",
    "            demo_augmentation_every_n=DEMO_AUGMENTATION_EVERY_N,\n",
    "            cameras=CAMERAS,\n",
    "            rlbench_scene_bounds=SCENE_BOUNDS,\n",
    "            voxel_sizes=VOXEL_SIZES,\n",
    "            rotation_resolution=ROTATION_RESOLUTION,\n",
    "            crop_augmentation=False,\n",
    "            depth_scale=DEPTH_SCALE,\n",
    "            use_approach=USE_APPROACH,\n",
    "            approach_distance=0.3,\n",
    "            stopping_delta=STOPPING_DELTA,\n",
    "            target_obj_keypoint=TARGET_OBJ_KEYPOINTS,\n",
    "            target_obj_use_last_kp=TARGET_OBJ_USE_LAST_KP,\n",
    "            target_obj_is_avail=TARGET_OBJ_IS_AVAIL,\n",
    "            clip_model=clip_model,\n",
    "            device=device,\n",
    "            )\n",
    "    elif FILL_REPLAY_SETTING.lower() == \"crop\":\n",
    "        fill_replay_copy_with_crop_from_approach(\n",
    "            data_path=test_data_path,\n",
    "            episode_folder=EPISODE_FOLDER,\n",
    "            replay=test_replay_buffer,\n",
    "            # start_idx=start_idx,\n",
    "            # num_demos=num_demos,\n",
    "            d_indexes=TEST_INDEXES,\n",
    "            demo_augmentation=True,\n",
    "            demo_augmentation_every_n=DEMO_AUGMENTATION_EVERY_N,\n",
    "            cameras=CAMERAS,\n",
    "            rlbench_scene_bounds=SCENE_BOUNDS,\n",
    "            voxel_sizes=VOXEL_SIZES,\n",
    "            rotation_resolution=ROTATION_RESOLUTION,\n",
    "            crop_augmentation=False,\n",
    "            depth_scale=DEPTH_SCALE,\n",
    "            use_approach=USE_APPROACH,\n",
    "            approach_distance=0.3,\n",
    "            stopping_delta=STOPPING_DELTA,\n",
    "            target_obj_keypoint=TARGET_OBJ_KEYPOINTS,\n",
    "            target_obj_use_last_kp=TARGET_OBJ_USE_LAST_KP,\n",
    "            target_obj_is_avail=TARGET_OBJ_IS_AVAIL,\n",
    "            clip_model=clip_model,\n",
    "            device=device,\n",
    "            )\n",
    "    elif FILL_REPLAY_SETTING.lower() == \"standard\":\n",
    "        fill_replay_only_approach_test(\n",
    "        # fill_replay(\n",
    "            data_path=test_data_path,\n",
    "            episode_folder=EPISODE_FOLDER,\n",
    "            replay=test_replay_buffer,\n",
    "            # start_idx=start_idx,\n",
    "            # num_demos=num_demos,\n",
    "            d_indexes=TEST_INDEXES,\n",
    "            demo_augmentation=True,\n",
    "            demo_augmentation_every_n=DEMO_AUGMENTATION_EVERY_N,\n",
    "            cameras=CAMERAS,\n",
    "            rlbench_scene_bounds=SCENE_BOUNDS,\n",
    "            voxel_sizes=VOXEL_SIZES,\n",
    "            rotation_resolution=ROTATION_RESOLUTION,\n",
    "            crop_augmentation=False,\n",
    "            depth_scale=DEPTH_SCALE,\n",
    "            use_approach=USE_APPROACH,\n",
    "            approach_distance=0.3,\n",
    "            stopping_delta=STOPPING_DELTA,\n",
    "            target_obj_keypoint=TARGET_OBJ_KEYPOINTS,\n",
    "            target_obj_use_last_kp=TARGET_OBJ_USE_LAST_KP,\n",
    "            target_obj_is_avail=TARGET_OBJ_IS_AVAIL,\n",
    "            clip_model=clip_model,\n",
    "            device=device,\n",
    "            )\n",
    "    else:\n",
    "        raise ValueError(\"Unkown setting for fill replay buffer\")\n",
    "\n",
    "    # delete the CLIP model since we have already extracted language features\n",
    "    del clip_model\n",
    "\n",
    "    # wrap buffer with PyTorch dataset and make iterator\n",
    "    train_wrapped_replay = PyTorchReplayBuffer(train_replay_buffer)\n",
    "    train_dataset = train_wrapped_replay.dataset()\n",
    "    train_data_iter = iter(train_dataset)\n",
    "\n",
    "    test_wrapped_replay = PyTorchReplayBuffer(test_replay_buffer)\n",
    "    test_dataset = test_wrapped_replay.dataset()\n",
    "    test_data_iter = iter(test_dataset)\n",
    "\n",
    "    #___AGENT___\n",
    "\n",
    "    perceiver_encoder = PerceiverIO(\n",
    "        depth=6,\n",
    "        iterations=1,\n",
    "        voxel_size=VOXEL_SIZES[0],\n",
    "        initial_dim=3 + 3 + 1 + 3,\n",
    "        low_dim_size=4,\n",
    "        layer=0,\n",
    "        num_rotation_classes=72,\n",
    "        num_grip_classes=2,\n",
    "        num_collision_classes=2,\n",
    "        num_latents=NUM_LATENTS,\n",
    "        latent_dim=512,\n",
    "        cross_heads=1,\n",
    "        latent_heads=8,\n",
    "        cross_dim_head=64,\n",
    "        latent_dim_head=64,\n",
    "        weight_tie_layers=False,\n",
    "        activation='lrelu',\n",
    "        input_dropout=0.1,\n",
    "        attn_dropout=0.1,\n",
    "        decoder_dropout=0.0,\n",
    "        voxel_patch_size=5,\n",
    "        voxel_patch_stride=5,\n",
    "        final_dim=64,\n",
    "    )\n",
    "\n",
    "    peract_agent = PerceiverActorAgent(\n",
    "        coordinate_bounds=SCENE_BOUNDS,\n",
    "        perceiver_encoder=perceiver_encoder,\n",
    "        camera_names=CAMERAS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        voxel_size=VOXEL_SIZES[0],\n",
    "        voxel_feature_size=3,\n",
    "        num_rotation_classes=72,\n",
    "        rotation_resolution=ROTATION_RESOLUTION,\n",
    "        training_iterations = TRAINING_ITERATIONS,\n",
    "        lr=LEARNING_RATE,\n",
    "        lr_scheduler=LR_SCHEDULER,\n",
    "        num_warmup_steps = NUM_WARMUP_STEPS,\n",
    "        num_cycles = NUM_CYCLES,\n",
    "        image_resolution=[IMAGE_SIZE, IMAGE_SIZE],\n",
    "        lambda_weight_l2=0.000001,\n",
    "        transform_augmentation=TRANSFORM_AUGMENTATION,\n",
    "        rgb_augmentation=RGB_AUGMENTATION,\n",
    "        optimizer_type='lamb',\n",
    "    )\n",
    "    peract_agent.build(training=True, device=device)\n",
    "\n",
    "    #___TRAINING___\n",
    "\n",
    "    LOCAL_FREQ = 10\n",
    "    SAVE_MODELS = True\n",
    "    GLOBAL_FREQ = 1000\n",
    "    calc_test_loss = True\n",
    "\n",
    "    # Misc\n",
    "    train_loss = 1e8\n",
    "    test_loss = 1e8\n",
    "    general_loss = [1e8,1e8]\n",
    "\n",
    "    # Directories where to save the best models for train/test\n",
    "    model_run_time = datetime.now()\n",
    "    model_save_dir = os.path.join(WORKSPACE_DIR,\"outputs\", \"models\", TASK, model_run_time.strftime(\"%Y-%m-%d_%H-%M\"))\n",
    "\n",
    "    model_save_dir_iter = os.path.join(model_save_dir, \"run%d\")\n",
    "\n",
    "    model_save_dir_best_general_iter = os.path.join(model_save_dir_iter, \"best_model_general\")\n",
    "    model_save_dir_best_train_iter = os.path.join(model_save_dir_iter, \"best_model_train\")\n",
    "    model_save_dir_best_test_iter = os.path.join(model_save_dir_iter, \"best_model_test\")\n",
    "    model_save_dir_last_iter = os.path.join(model_save_dir_iter, \"last_model\")\n",
    "    metrics_save_path_iter = os.path.join(model_save_dir_iter, \"training_metrics.json\")  # JSON file to save metrics\n",
    "\n",
    "    metrics_save_path = os.path.join(model_save_dir, \"training_metrics.json\")  # JSON file to save metrics\n",
    "    settings_save_path = os.path.join(model_save_dir, \"training_settings.json\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Initialize metrics dictionary\n",
    "    metrics = {\n",
    "        \"train\": [],\n",
    "        \"test\": []\n",
    "    }\n",
    "\n",
    "    for iteration in range(TRAINING_ITERATIONS):\n",
    "        \n",
    "        batch = next(train_data_iter)\n",
    "        batch = {k: v.to(device) for k, v in batch.items() if type(v) == torch.Tensor}\n",
    "        update_dict = peract_agent.update(iteration, batch) # Here backprop == True: for training reaons, hence training_loss == total_loss\n",
    "\n",
    "        if iteration % LOCAL_FREQ == 0:\n",
    "            elapsed_time = (time.time() - start_time) / 60.0\n",
    "\n",
    "            # Log training metrics\n",
    "            train_metrics = {\n",
    "                \"iteration\": iteration,\n",
    "                \"learning_rate\": update_dict['learning_rate'],\n",
    "                \"total_loss\": update_dict['total_loss'],\n",
    "                \"trans_loss\": update_dict['trans_loss'],\n",
    "                \"rot_loss\": update_dict['rot_loss'],\n",
    "                \"col_loss\": update_dict['col_loss'],\n",
    "                \"elapsed_time\": elapsed_time\n",
    "            }\n",
    "            metrics[\"train\"].append(train_metrics)\n",
    "\n",
    "            if calc_test_loss:\n",
    "                batch = next(test_data_iter)\n",
    "                batch = {k: v.to(device) for k, v in batch.items() if type(v) == torch.Tensor}\n",
    "                test_update_dict = peract_agent.update(iteration, batch, backprop=False) # Here backprop == False: for evaluation, hence test_loss == total_loss\n",
    "\n",
    "                # Log test metrics\n",
    "                test_metrics = {\n",
    "                    \"iteration\": iteration,\n",
    "                    \"total_loss\": test_update_dict['total_loss'],\n",
    "                    \"trans_loss\": test_update_dict['trans_loss'],\n",
    "                    \"rot_loss\": test_update_dict['rot_loss'],\n",
    "                    \"col_loss\": test_update_dict['col_loss']\n",
    "                }\n",
    "                metrics[\"test\"].append(test_metrics)\n",
    "\n",
    "                print(\"Iteration: %d/%d | Learning Rate: %f | Train Loss [tot,trans,rot,col]: [%0.2f, %0.2f, %0.2f, %0.2f] | Test Loss [tot,trans,rot,col]: [%0.2f, %0.2f, %0.2f, %0.2f] | Elapsed Time: %0.2f mins\"\\\n",
    "                    % (iteration, TRAINING_ITERATIONS, \n",
    "                        update_dict['learning_rate'],\n",
    "                        update_dict['total_loss'], update_dict['trans_loss'], update_dict['rot_loss'], update_dict['col_loss'],\n",
    "                        test_update_dict['total_loss'], test_update_dict['trans_loss'], test_update_dict['rot_loss'], test_update_dict['col_loss'], \n",
    "                        elapsed_time))\n",
    "            else:\n",
    "                print(\"Iteration: %d/%d | Learning Rate: %f| Train Loss [tot,trans,rot,col]: [%0.2f, %0.2f, %0.2f, %0.2f] | Elapsed Time: %0.2f mins\"\\\n",
    "                    % (iteration, TRAINING_ITERATIONS, \n",
    "                        update_dict['learning_rate'],\n",
    "                        update_dict['total_loss'], update_dict['trans_loss'], update_dict['rot_loss'], update_dict['col_loss'],\n",
    "                        elapsed_time))\n",
    "                \n",
    "            if (SAVE_MODELS == True):\n",
    "                save_model_freq_iter_number = (iteration // GLOBAL_FREQ) * GLOBAL_FREQ\n",
    "\n",
    "                model_save_dir_general_iteration = model_save_dir_best_general_iter % save_model_freq_iter_number\n",
    "                model_save_dir_best_train_iteration = model_save_dir_best_train_iter % save_model_freq_iter_number\n",
    "                model_save_dir_best_test_iteration = model_save_dir_best_test_iter % save_model_freq_iter_number\n",
    "\n",
    "                # Create directories\n",
    "                if not os.path.exists(model_save_dir_general_iteration):\n",
    "                    print(f\"Could not find {model_save_dir_general_iteration}, creating directory.\")\n",
    "                    os.makedirs(model_save_dir_general_iteration)\n",
    "                if not os.path.exists(model_save_dir_best_train_iteration):\n",
    "                    print(f\"Could not find {model_save_dir_best_train_iteration}, creating directory.\")\n",
    "                    os.makedirs(model_save_dir_best_train_iteration)\n",
    "                if not os.path.exists(model_save_dir_best_test_iteration):\n",
    "                    print(f\"Could not find {model_save_dir_best_test_iteration}, creating directory.\")\n",
    "                    os.makedirs(model_save_dir_best_test_iteration)\n",
    "                    \n",
    "                # Only save the best if better\n",
    "                if update_dict['total_loss'] < general_loss[0] and test_update_dict['total_loss'] < general_loss[1]:\n",
    "                    print(\"Saving Best Model - General\")\n",
    "                    general_loss = [update_dict['total_loss'], test_update_dict['total_loss']]\n",
    "                    peract_agent.save_weights(model_save_dir_general_iteration)\n",
    "                if update_dict['total_loss'] < train_loss:\n",
    "                    print(\"Saving Best Model - Train\")\n",
    "                    train_loss = update_dict['total_loss']\n",
    "                    peract_agent.save_weights(model_save_dir_best_train_iteration)\n",
    "                if test_update_dict['total_loss'] < test_loss:\n",
    "                    print(\"Saving Best Model - Test\")\n",
    "                    test_loss = test_update_dict['total_loss']\n",
    "                    peract_agent.save_weights(model_save_dir_best_test_iteration)\n",
    "            \n",
    "                if (iteration+LOCAL_FREQ) % GLOBAL_FREQ == 0:# and iteration // GLOBAL_FREQ: #0-500 -> 0, 500-1000 -> 1\n",
    "                    save_model_freq_iter_number = (iteration // GLOBAL_FREQ) * GLOBAL_FREQ\n",
    "\n",
    "                    # Save last checkpoint\n",
    "                    model_save_dir_last_iteration = model_save_dir_last_iter%save_model_freq_iter_number\n",
    "                    metrics_save_path_iteration = metrics_save_path_iter%save_model_freq_iter_number\n",
    "\n",
    "                    if not os.path.exists(model_save_dir_last_iteration):\n",
    "                        print(f\"Could not find {model_save_dir_last_iteration}, creating directory.\")\n",
    "                        os.makedirs(model_save_dir_last_iteration)\n",
    "\n",
    "                    print(f\"Saving Model - Last stage: {save_model_freq_iter_number}\")\n",
    "                    peract_agent.save_weights(model_save_dir_last_iteration)\n",
    "\n",
    "                    # Save metrics to JSON file\n",
    "                    with open(metrics_save_path_iteration, 'w') as f:\n",
    "                        json.dump(metrics, f, indent=4, cls=NumpyEncoder)\n",
    "\n",
    "    # Save metrics to JSON file\n",
    "    with open(metrics_save_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=4, cls=NumpyEncoder)\n",
    "\n",
    "    # Save training settings to JSON file\n",
    "    with open(settings_save_path, 'w') as f:\n",
    "        json.dump(settings, f, indent=4, cls=NumpyEncoder)\n",
    "\n",
    "    print(f\"Training metrics and settings saved to {metrics_save_path} and {settings_save_path}\")\n",
    "\n",
    "    del peract_agent\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super().default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "available_cameras = [f\"view_{camera_i}\" for camera_i in range(3)]\n",
    "# Grid search\n",
    "grid = {\n",
    "    'fill_replay_setting': [\"standard\"],#, \"standard\", \"uniform\"],\n",
    "    'cameras': [available_cameras],# [available_cameras[0]]],\n",
    "    'RGB_AUGMENTATION': ['None','partial','full'],\n",
    "    'demo_augm_n': [5],\n",
    "    'keypoint_approach': [True],#, False],\n",
    "    'only_learn_approach': [True]\n",
    "}\n",
    "# Loop over al grid search combinations\n",
    "counter = 0\n",
    "lst_settings = []\n",
    "for values in itertools.product(*grid.values()):\n",
    "    \n",
    "    point = dict(zip(grid.keys(), values))\n",
    "    # merge the general settings\n",
    "    settings = {**point}\n",
    "    lst_settings.append(settings)\n",
    "    print(counter, settings)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over al grid search combinations: and run\n",
    "for run_settings in lst_settings:\n",
    "    print(run_settings)\n",
    "\n",
    "    train_peract_agent(run_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For single (test) run\n",
    "# available_cameras = [f\"view_{camera_i}\" for camera_i in range(3)]\n",
    "# run_settings = {\n",
    "#     'fill_replay_setting': \"crop\",\n",
    "#     'cameras': available_cameras,\n",
    "#     'RGB_AUGMENTATION': 'partial',\n",
    "#     'keypoint_approach': True,\n",
    "#     'demo_augm_n': 5,\n",
    "#     'only_learn_approach': True\n",
    "# }\n",
    "# print(run_settings)\n",
    "\n",
    "# train_peract_agent(run_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
